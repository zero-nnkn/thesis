% Background...:)
@article{LeCun-NC1989-Backpropagation,
	title        = {Backpropagation applied to handwritten zip code recognition},
	author       = {LeCun, Yann and Boser, Bernhard and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne and Jackel, Lawrence D},
	year         = 1989,
	journal      = {Neural computation},
	volume       = 1,
	number       = 4,
	pages        = {541--551},
}
@article{Dumoulin-ArXiv2016-Guide,
	title        = {A guide to convolution arithmetic for deep learning},
	author       = {Dumoulin, Vincent and Visin, Francesco},
	year         = 2016,
	journal      = {arXiv preprint arXiv:1603.07285},
}
@book{Goodfellow-MIT2016-DL,
	title        = {Deep Learning},
	author       = {Ian J. Goodfellow and Yoshua Bengio and Aaron Courville},
	year         = 2016,
	publisher    = {MIT Press},
	address      = {Cambridge, MA, USA},
	note         = {\url{http://www.deeplearningbook.org}},
}
@book{Rudin-McGrawHill1991-Functional,
	title        = {Functional Analysis},
	author       = {Rudin, W.},
	year         = 1991,
	publisher    = {McGraw-Hill},
	series       = {International series in pure and applied mathematics},
	isbn         = 9780070542365,
	url          = {https://books.google.com.vn/books?id=Sh\_vAAAAMAAJ},
	lccn         = {lc90005677},
}
@misc{Stanford-CS231n,
	title        = {CS231n: Deep Learning for Computer Vision},
	note         = {Accessed: 2023-07-17},
	howpublished = {\url{http://cs231n.stanford.edu/}},
}
@inproceedings{Zhou-ECCV2016-AppearanceFlow,
	title        = {View synthesis by appearance flow},
	author       = {Zhou, Tinghui and Tulsiani, Shubham and Sun, Weilun and Malik, Jitendra and Efros, Alexei A},
	year         = 2016,
	booktitle    = {European Conference on Computer Vision (ECCV)},
	pages        = {286--301},
}
@inproceedings{Song-ICCV2017-Crest,
	title        = {Crest: Convolutional residual learning for visual tracking},
	author       = {Song, Yibing and Ma, Chao and Gong, Lijun and Zhang, Jiawei and Lau, Rynson WH and Yang, Ming-Hsuan},
	year         = 2017,
	booktitle    = {IEEE International Conference on Computer Vision (ICCV)},
	pages        = {2555--2564},
}
@inproceedings{Li-CVPR2019-Dense,
	title        = {Dense intrinsic appearance flow for human pose transfer},
	author       = {Li, Yining and Huang, Chen and Loy, Chen Change},
	year         = 2019,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {3693--3702},
}
@inproceedings{Liu-ECCV2020-Rethinking,
	title        = {Rethinking image inpainting via a mutual encoder-decoder with feature equalizations},
	author       = {Liu, Hongyu and Jiang, Bin and Song, Yibing and Huang, Wei and Yang, Chao},
	year         = 2020,
	booktitle    = {European Conference on Computer Vision (ECCV)},
	pages        = {725--741},
}
% Overview
@misc{Fashion2327-Statista2023,
	title        = {Fashion e-commerce market value worldwide from 2023 to 2027},
	note         = {Accessed: 2023-06-29},
	howpublished = {\url{https://www.statista.com/topics/9288/fashion-e-commerce-worldwide}},
}
%% Commercial product
@misc{GoogleVTO-GoogleBlog2023-Clothes,
	title        = {Google introduces new AI virtual try-on feature},
	note         = {Accessed: 2023-06-29},
	howpublished = {\url{https://blog.google/products/shopping/ai-virtual-try-on-google-shopping}},
}
@misc{ZalandoVTO-Zalando2023-Clothes,
	title        = {Zalando brings a virtual fitting room pilot to millions of customers},
	note         = {Accessed: 2023-06-29},
	howpublished = {\url{https://corporate.zalando.com/en/technology/zalando-brings-virtual-fitting-room-pilot-millions-customers}},
}
@misc{GeeneeVTO-Clothes,
	title        = {Geenee AR},
	note         = {Accessed: 2023-06-29},
	howpublished = {\url{https://geenee.ar/}},
}
@misc{AmazonVTO-Aboutamazon2022-Shoes,
	title        = {Amazon makes shopping easier with Virtual Try-On for Shoes},
	note         = {Accessed: 2023-06-29},
	howpublished = {\url{https://www.aboutamazon.com/news/retail/amazon-makes-shopping-easier-with-virtual-try-on-for-shoes}},
}
@misc{Artlabs-Shoes,
	title        = {Artlabs},
	note         = {Accessed: 2023-06-29},
	howpublished = {\url{https://artlabs.ai/virtual-try-on}},
}
@misc{BaumeMercierr-TimeTide-Watch,
	title        = {Baume \& Mercier updates their digital sales experience with the Virtual Try-On System},
	note         = {Accessed: 2023-06-29},
	howpublished = {\url{https://timeandtidewatches.com/baume-mercier-virtual-try-on-system}},
}
@misc{BaumeMercierr-Hapticmedia-Watch,
	title        = {Interview : Our Virtual Try-on project for Baume \& Mercier Riviera watch},
	note         = {Accessed: 2023-06-29},
	howpublished = {\url{https://hapticmedia.com/blog/riviera-try-on-interview}},
}
@misc{WarbyParker-Glasses,
	title        = {WarbyParker},
	note         = {Accessed: 2023-06-29},
	howpublished = {\url{https://www.warbyparker.com}},
}
@misc{WarbyParker-Insider-Glasses,
	title        = {I tried Warby Parker's new feature that lets you try on glasses virtually and the results were surprisingly life like},
	note         = {Accessed: 2023-06-29},
	howpublished = {\url{https://www.insider.com/guides/style/warby-parker-virtual-try-on-app-review}},
}
% TRANSFORMER
@article{Vaswani-NeurIPS2017-Attention,
	title        = {Attention is all you need},
	author       = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
	year         = 2017,
	journal      = {Advances in neural information processing systems (NeurIPS)},
	volume       = 30,
	number       = {},
	pages        = {6000–6010},
}
@article{Devlin-ArXiv2018-BERT,
	title        = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	author       = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	year         = 2018,
	journal      = {arXiv preprint arXiv:1810.04805},
}
@article{Radford-OpenAIblog2019-Language,
	title        = {Language models are unsupervised multitask learners},
	author       = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
	year         = 2019,
	journal      = {OpenAI blog},
	volume       = 1,
	number       = 8,
	pages        = 9,
}
@article{Brown-NeurIPS2020-Language,
	title        = {Language models are few-shot learners},
	author       = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
	year         = 2020,
	journal      = {Advances in neural information processing systems (NeurIPS)},
	volume       = 33,
	number       = {},
	pages        = {1877--1901},
}
@article{Dosovitskiy-ArXiv2020-image,
	title        = {An image is worth 16x16 words: Transformers for image recognition at scale},
	author       = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2010.11929},
}
% FASHION RECOMMENDATION
@inproceedings{Radford-ICML2021-Learning,
	title        = {Learning transferable visual models from natural language supervision},
	author       = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
	year         = 2021,
	booktitle    = {International Conference on Machine Learning (ICML)},
	pages        = {8748--8763},
}
@inproceedings{Baldrati-CVPR2022-Effective,
	title        = {Effective Conditioned and Composed Image Retrieval Combining CLIP-Based Features},
	author       = {Baldrati, Alberto and Bertini, Marco and Uricchio, Tiberio and Del Bimbo, Alberto},
	year         = 2022,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {21466--21474},
}
@inproceedings{Baldrati-CVPR2022-Conditioned,
	title        = {Conditioned and Composed Image Retrieval Combining and Partially Fine-Tuning CLIP-Based Features},
	author       = {Baldrati, Alberto and Bertini, Marco and Uricchio, Tiberio and Del Bimbo, Alberto},
	year         = 2022,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {4959--4968},
}
@inproceedings{Mariya-ECCV18-Learning,
	title        = {Learning Type-Aware Embeddings for Fashion Compatibility},
	author       = {Mariya I. Vasileva and Bryan A. Plummer and Krishna Dusad and Shreya Rajpal and Ranjitha Kumar and David Forsyth},
	year         = 2018,
	booktitle    = {European Conference on Computer Vision (ECCV)},
	pages        = {405--421},
}
@inproceedings{Lin-CVPR2020-Fashion,
	title        = {Fashion Outfit Complementary Item Retrieval},
	author       = {Yen-Liang Lin and Son Tran and Larry Davis},
	year         = 2020,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {3311--3319},
}
@inproceedings{Sarkar-CVPRW2022-OutfitTransformer,
	title        = {OutfitTransformer: Outfit Representations for Fashion Recommendation},
	author       = {Sarkar, Rohan and Bodla, Navaneeth and Vasileva, Mariya and Lin, Yen-Liang and Beniwal, Anurag and Lu, Alan and Medioni, Gerard},
	year         = 2022,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
	pages        = {2262--2266},
}
@inproceedings{Han-ECCV2022-FashionViL,
	title        = {FashionViL: Fashion-Focused Vision-and-Language Representation Learning},
	author       = {Han, Xiao and Yu, Licheng and Zhu, Xiatian and Zhang, Li and Song, Yi-Zhe and Xiang, Tao},
	year         = 2022,
	booktitle    = {European Conference on Computer Vision (ECCV)},
	pages        = {634–651},
}
@inproceedings{Gionis-VLDB1999-Similarity,
	title        = {Similarity search in high dimensions via hashing},
	author       = {Gionis, Aristides and Indyk, Piotr and Motwani, Rajeev and others},
	year         = 1999,
	booktitle    = {International Conference on Very Large Data Bases (VLDB)},
	pages        = {518--529},
}
@article{Jegou-TPAMI2010-Product,
	title        = {Product quantization for nearest neighbor search},
	author       = {Jegou, Herve and Douze, Matthijs and Schmid, Cordelia},
	year         = 2010,
	journal      = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume       = 33,
	number       = 1,
	pages        = {117--128},
}
@inproceedings{Sivic-ICCV2003-Video,
	title        = {Video Google: A text retrieval approach to object matching in videos},
	author       = {Sivic and Zisserman},
	year         = 2003,
	booktitle    = {IEEE International Conference on Computer Vision (ICCV)},
	pages        = {1470--1477},
}
@article{Malkov-TPAMI2018-Efficient,
	title        = {Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs},
	author       = {Malkov, Yu A and Yashunin, Dmitry A},
	year         = 2018,
	journal      = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume       = 42,
	number       = 4,
	pages        = {824--836},
}
@manual{Erik-Github-Annoy,
	title        = {Annoy: Approximate Nearest Neighbors in C++/Python},
	author       = {Erik Bernhardsson},
	year         = 2018,
	url          = {https://pypi.org/project/annoy/},
	note         = {Python package version 1.13.0},
}
@misc{Bhatia-Github-Keytotext,
	title        = {keytotext},
	author       = {Bhatia, Gagan},
	journal      = {GitHub},
	url          = {https://github.com/gagan3012/keytotext},
}
@inproceedings{Liu-CVPR2016-DeepFashion,
	title        = {DeepFashion: Powering Robust Clothes Recognition and Retrieval with Rich Annotations},
	author       = {Liu, Ziwei and Luo, Ping and Qiu, Shi and Wang, Xiaogang and Tang, Xiaoou},
	year         = 2016,
	booktitle    = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {1096--1104},
}
%% LOSS
@article{Lai-Arxiv2019-Contrastive,
	title        = {Contrastive Predictive Coding Based Feature for Automatic Speaker Verification},
	author       = {Lai, Cheng-I},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1904.01575},
}
% VIRTUAL TRY-ON
@inproceedings{Xu-ISMAR2019-3d,
	title        = {3d virtual garment modeling from rgb images},
	author       = {Xu, Yi and Yang, Shanglin and Sun, Wei and Tan, Li and Li, Kefeng and Zhou, Hui},
	year         = 2019,
	booktitle    = {IEEE International Symposium on Mixed and Augmented Reality (ISMAR)},
	pages        = {37--45},
}
@inproceedings{Pastel-CVPR2020-Tailornet,
	title        = {Tailornet: Predicting clothing in 3d as a function of human pose, shape and garment style},
	author       = {Patel, Chaitanya and Liao, Zhouyingcheng and Pons-Moll, Gerard},
	year         = 2020,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {7365--7375},
}
@inproceedings{Zhao-ICCV2021-M3d,
	title        = {M3d-vton: A monocular-to-3d virtual try-on network},
	author       = {Zhao, Fuwei and Xie, Zhenyu and Kampffmeyer, Michael and Dong, Haoye and Han, Songfang and Zheng, Tianxiang and Zhang, Tao and Liang, Xiaodan},
	year         = 2021,
	booktitle    = {IEEE/CVF International Conference on Computer Vision (ICCV)},
	pages        = {13239--13249},
}
@inproceedings{Han-CVPR2018-Viton,
	title        = {Viton: An image-based virtual try-on network},
	author       = {Han, Xintong and Wu, Zuxuan and Wu, Zhe and Yu, Ruichi and Davis, Larry S},
	year         = 2018,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {7543--7552},
}
@inproceedings{Wang-ECCV2018-Toward,
	title        = {Toward characteristic-preserving image-based virtual try-on network},
	author       = {Wang, Bochao and Zheng, Huabin and Liang, Xiaodan and Chen, Yimin and Lin, Liang and Yang, Meng},
	year         = 2018,
	booktitle    = {European Conference on Computer Vision (ECCV)},
	pages        = {589--604},
}
@inproceedings{Han-ICCV2019-Clothflow,
	title        = {Clothflow: A flow-based model for clothed person generation},
	author       = {Han, Xintong and Hu, Xiaojun and Huang, Weilin and Scott, Matthew R},
	year         = 2019,
	booktitle    = {IEEE/CVF International Conference on Computer Vision (ICCV)},
	pages        = {10471--10480},
}
@inproceedings{Yang-CVPR2020-Towards,
	title        = {Towards photo-realistic virtual try-on by adaptively generating-preserving image content},
	author       = {Yang, Han and Zhang, Ruimao and Guo, Xiaobao and Liu, Wei and Zuo, Wangmeng and Luo, Ping},
	year         = 2020,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {7850--7859},
}
@inproceedings{Issenhuth-ECCV2020-Do,
	title        = {Do not mask what you do not need to mask: a parser-free virtual try-on},
	author       = {Issenhuth, Thibaut and Mary, J{\'e}r{\'e}mie and Calauzenes, Cl{\'e}ment},
	year         = 2020,
	booktitle    = {European Conference on Computer Vision (ECCV)},
	pages        = {619--635},
}
@inproceedings{Bai-ECCV2022-Single,
	title        = {Single stage virtual try-on via deformable attention flows},
	author       = {Bai, Shuai and Zhou, Huiling and Li, Zhikang and Zhou, Chang and Yang, Hongxia},
	year         = 2022,
	booktitle    = {European Conference on Computer Vision (ECCV)},
	pages        = {409--425},
}
@inproceedings{Ge-CVPR2021-Parser,
	title        = {Parser-free virtual try-on via distilling appearance flows},
	author       = {Ge, Yuying and Song, Yibing and Zhang, Ruimao and Ge, Chongjian and Liu, Wei and Luo, Ping},
	year         = 2021,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {8485--8493},
}
@inproceedings{He-CVPR2022-Style,
	title        = {Style-based global appearance flow for virtual try-on},
	author       = {He, Sen and Song, Yi-Zhe and Xiang, Tao},
	year         = 2022,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {3470--3479},
}
@inproceedings{Lin-IJCAI2022-RMGN,
	title        = {RMGN: A Regional Mask Guided Network for Parser-free Virtual Try-on},
	author       = {Lin, Chao and Li, Zhao and Zhou, Sheng and Hu, Shichang and Zhang, Jialun and Luo, Linhao and Zhang, Jiarun and Huang, Longtao and He, Yuan},
	year         = 2022,
	booktitle    = {International Joint Conference on Artificial Intelligence (IJCAI)},
	pages        = {1151--1158},
}
@inproceedings{Choi-CVPR2021-Viton,
	title        = {Viton-hd: High-resolution virtual try-on via misalignment-aware normalization},
	author       = {Choi, Seunghwan and Park, Sunghyun and Lee, Minsoo and Choo, Jaegul},
	year         = 2021,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {14131--14140},
}
@inproceedings{Morelli-CVPR2022-Dress,
	title        = {Dress Code: High-Resolution Multi-Category Virtual Try-On},
	author       = {Morelli, Davide and Fincato, Matteo and Cornia, Marcella and Landi, Federico and Cesari, Fabio and Cucchiara, Rita},
	year         = 2022,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {2231--2235},
}
@inproceedings{Karras-CVPR2019-Style,
	title        = {A style-based generator architecture for generative adversarial networks},
	author       = {Karras, Tero and Laine, Samuli and Aila, Timo},
	year         = 2019,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {4401--4410},
}
@inproceedings{Karras-CVPR2020-Analyzing,
	title        = {Analyzing and improving the image quality of stylegan},
	author       = {Karras, Tero and Laine, Samuli and Aittala, Miika and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
	year         = 2020,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {8110--8119},
}
@inproceedings{Jiang-CVPR2022-Clothformer,
	title        = {Clothformer: Taming video virtual try-on in all module},
	author       = {Jiang, Jianbin and Wang, Tan and Yan, He and Liu, Junhui},
	year         = 2022,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {10799--10808},
}
@inproceedings{Fele-WACV2022-CVTON,
	title        = {C-vton: Context-driven image-based virtual try-on network},
	author       = {Fele, Benjamin and Lampe, Ajda and Peer, Peter and Struc, Vitomir},
	year         = 2022,
	booktitle    = {IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
	pages        = {3144--3153},
}
@inproceedings{Zhong-ACMMM2021-Mvton,
	title        = {Mv-ton: Memory-based video virtual try-on network},
	author       = {Zhong, Xiaojing and Wu, Zhonghua and Tan, Taizhe and Lin, Guosheng and Wu, Qingyao},
	year         = 2021,
	booktitle    = {ACM Multimedia (ACMMM)},
	pages        = {908--916},
}
@inproceedings{Kuppa-WACVW2021-ShineOn,
	title        = {ShineOn: Illuminating design choices for practical video-based virtual clothing try-on},
	author       = {Kuppa, Gaurav and Jong, Andrew and Liu, Xin and Liu, Ziwei and Moh, Teng-Sheng},
	year         = 2021,
	booktitle    = {IEEE Winter Conference on Applications of Computer Vision Workshops (WACVW)},
	pages        = {191--200},
}
@inproceedings{Zhou-ECCV2022-Cross,
	title        = {Cross attention based style distribution for controllable person image synthesis},
	author       = {Zhou, Xinyue and Yin, Mingyu and Chen, Xinyuan and Sun, Li and Gao, Changxin and Li, Qingli},
	year         = 2022,
	booktitle    = {European Conference on Computer Vision (ECCV)},
	pages        = {161--178},
}
@article{Lin-ArXiv2023-FashionTex,
	title        = {FashionTex: Controllable Virtual Try-on with Text and Texture},
	author       = {Lin, Anran and Zhao, Nanxuan and Ning, Shuliang and Qiu, Yuda and Wang, Baoyuan and Han, Xiaoguang},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2305.04451},
}
%SIGGRAPH 2023
@article{Morelli-ArXiv2023-LaDIVTON,
	title        = {LaDI-VTON: Latent Diffusion Textual-Inversion Enhanced Virtual Try-On},
	author       = {Morelli, Davide and Baldrati, Alberto and Cartella, Giuseppe and Cornia, Marcella and Bertini, Marco and Cucchiara, Rita},
	year         = 2023,
	journal      = {arXiv preprint arXiv:2305.13501},
}
@inproceedings{Xie-CVPR2023-GPVTON,
	title        = {GP-VTON: Towards General Purpose Virtual Try-on via Collaborative Local-Flow Global-Parsing Learning},
	author       = {Xie, Zhenyu and Huang, Zaiyu and Dong, Xin and Zhao, Fuwei and Dong, Haoye and Zhang, Xijin and Zhu, Feida and Liang, Xiaodan},
	year         = 2023,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {23550--23559},
}
%% PREPROCESS
@inproceedings{Cao-CVPR2017-Realtime,
	title        = {Realtime multi-person 2d pose estimation using part affinity fields},
	author       = {Cao, Zhe and Simon, Tomas and Wei, Shih-En and Sheikh, Yaser},
	year         = 2017,
	booktitle    = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {7291--7299},
}
@inproceedings{Gong-CVPR2017-Look,
	title        = {Look into person: Self-supervised structure-sensitive learning and a new benchmark for human parsing},
	author       = {Gong, Ke and Liang, Xiaodan and Zhang, Dongyu and Shen, Xiaohui and Lin, Liang},
	year         = 2017,
	booktitle    = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {932--940},
}
@article{Li-TPAMI2020-Self,
	title        = {Self-correction for human parsing},
	author       = {Li, Peike and Xu, Yunqiu and Wei, Yunchao and Yang, Yi},
	year         = 2020,
	journal      = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume       = 44,
	number       = 6,
	pages        = {3260--3271},
}
@inproceedings{Guler-CVPR2018-DensePose,
	title        = {DensePose: Dense human pose estimation in the wild},
	author       = {Guler, RA and Neverova, Natalia and DensePose, IK},
	year         = 2018,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {7297--7306},
}
@article{Xu-Arxiv2022-Vitpose,
	title        = {Vitpose: Simple vision transformer baselines for human pose estimation},
	author       = {Xu, Yufei and Zhang, Jing and Zhang, Qiming and Tao, Dacheng},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2204.12484},
}
@inproceedings{Liu-CVPR2022-Cdgnet,
	title        = {Cdgnet: Class distribution guided network for human parsing},
	author       = {Liu, Kunliang and Choi, Ouk and Wang, Jianming and Hwang, Wonjun},
	year         = 2022,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {4473--4482},
}
@inproceedings{Wang-CVPR2023-YOLOv7,
	title        = {YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors},
	author       = {Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark},
	year         = 2023,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {7464--7475},
}
%% BACKBONE
@inproceedings{Lin-CVPR2017-FPN,
	title        = {Feature pyramid networks for object detection},
	author       = {Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
	year         = 2017,
	booktitle    = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {2117--2125},
}
@inproceedings{Sandler-CVPR2018-Mobilenetv2,
	title        = {Mobilenetv2: Inverted residuals and linear bottlenecks},
	author       = {Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
	year         = 2018,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {4510--4520},
}
@inproceedings{Ronneberger-MICCAI2015-UNet,
	title        = {U-net: Convolutional networks for biomedical image segmentation},
	author       = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	year         = 2015,
	booktitle    = {Medical Image Computing and Computer Assisted Intervention (MICCAI)},
	pages        = {234--241},
}
%% LOSS
@article{Sun-IJCV2014-Quantitative,
	title        = {A quantitative analysis of current practices in optical flow estimation and the principles behind them},
	author       = {Sun, Deqing and Roth, Stefan and Black, Michael J},
	year         = 2014,
	journal      = {International Journal of Computer Vision (IJCV)},
	volume       = 106,
	number       = {},
	pages        = {115--137},
}
@inproceedings{Johnson-ECCV2016-Perceptual,
	title        = {Perceptual losses for real-time style transfer and super-resolution},
	author       = {Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
	year         = 2016,
	booktitle    = {European Conference on Computer Vision (ECCV)},
	pages        = {694--711},
}
@article{Simonyan-ArXiv2014-VGG,
	title        = {Very deep convolutional networks for large-scale image recognition},
	author       = {Simonyan, Karen and Zisserman, Andrew},
	year         = 2014,
	journal      = {arXiv preprint arXiv:1409.1556},
}
%% METRIC
@article{Heusel-NeurIPS2017-FID,
	title        = {Gans trained by a two time-scale update rule converge to a local nash equilibrium},
	author       = {Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
	year         = 2017,
	journal      = {Advances in neural information processing systems (NeurIPS)},
	volume       = 30,
	number       = {},
	pages        = {6629–6640},
}
@inproceedings{Zhang-CVPR2018-LPIPS,
	title        = {The unreasonable effectiveness of deep features as a perceptual metric},
	author       = {Zhang, Richard and Isola, Phillip and Efros, Alexei A and Shechtman, Eli and Wang, Oliver},
	year         = 2018,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {586--595},
}
% DIFFUSION
@inproceedings{Bhunia-CVPR2023-Person,
	title        = {Person image synthesis via denoising diffusion model},
	author       = {Bhunia, Ankan Kumar and Khan, Salman and Cholakkal, Hisham and Anwer, Rao Muhammad and Laaksonen, Jorma and Shah, Mubarak and Khan, Fahad Shahbaz},
	year         = 2023,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {5968--5976},
}
@article{Hinton-Arxiv2015-Distilling,
	title        = {Distilling the knowledge in a neural network},
	author       = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
	year         = 2015,
	journal      = {arXiv preprint arXiv:1503.02531},
}
@inproceedings{Han-ACMMM2017-Polyvore,
	title        = {Learning fashion compatibility with bidirectional lstms},
	author       = {Han, Xintong and Wu, Zuxuan and Jiang, Yu-Gang and Davis, Larry S},
	year         = 2017,
	booktitle    = {ACM Multimedia (ACMMM)},
	pages        = {1078--1086},
}
@inproceedings{Wu-CVPR2021-FashionIQ,
	title        = {Fashion IQ: A new dataset towards retrieving images by natural language feedback},
	author       = {Wu, Hui and Gao, Yupeng and Guo, Xiaoxiao and Al-Halah, Ziad and Rennie, Steven and Grauman, Kristen and Feris, Rogerio},
	year         = 2021,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {11307--11317},
}
% OTHERS
@inproceedings{Lin-ECCV2014-Microsoft,
	title        = {Microsoft coco: Common objects in context},
	author       = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
	year         = 2014,
	booktitle    = {European Conference on Computer Vision (ECCV)},
	pages        = {740--755},
}
@inproceedings{Park-CVPR2019-Semantic,
	title        = {Semantic Image Synthesis with Spatially-Adaptive Normalization},
	author       = {Park, Taesung and Liu, Ming-Yu and Wang, Ting-Chun and Zhu, Jun-Yan},
	year         = 2019,
	booktitle    = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {2337--2346},
}
@article{graves-Springer2012-lstm,
	title        = {Long short-term memory},
	author       = {Graves, Alex and Graves, Alex},
	year         = 2012,
	journal      = {Supervised sequence labelling with recurrent neural networks},
	publisher    = {Springer},
	volume       = {},
	number       = {},
	pages        = {37--45},
}
@inproceedings{Jegou-ICASSP2011-IVFPQ,
	title        = {Searching in one billion vectors: re-rank with source coding},
	author       = {J{\'e}gou, Herv{\'e} and Tavenard, Romain and Douze, Matthijs and Amsaleg, Laurent},
	year         = 2011,
	booktitle    = {IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages        = {861--864},
}
@article{johnson-bigdata2019-faiss,
	title        = {Billion-scale similarity search with {GPUs}},
	author       = {Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
	year         = 2019,
	journal      = {IEEE Transactions on Big Data},
	volume       = 7,
	number       = 3,
	pages        = {535--547},
}
@article{Paszke-NeurIPS2019-Pytorch,
	title        = {Pytorch: An imperative style, high-performance deep learning library},
	author       = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
	year         = 2019,
	journal      = {Advances in neural information processing systems (NeurIPS)},
	volume       = 32,
	number       = {},
	pages        = {8026--8037},
}
@misc{web-transform-from-scratch,
	title        = {Transformers from scratch},
	note         = {Accessed: 2023-06-29},
	howpublished = {\url{https://peterbloem.nl/blog/transformers}},
}
@misc{web-bert,
	title        = {Text classification using BERT},
	note         = {Accessed: 2023-06-29},
	howpublished = {\url{https://www.cse.chalmers.se/~richajo/nlp2019/l5/Text%20classification%20using%20BERT.html}},
}
@article{Dosovitskiy-Arxiv2020-Vit,
	title        = {An image is worth 16x16 words: Transformers for image recognition at scale},
	author       = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2010.11929},
}
@misc{web-pq,
	title        = {Product Quantizers for k-NN Tutorial Part 1},
	note         = {Accessed: 2023-07-17},
	howpublished = {\url{https://mccormickml.com/2017/10/13/product-quantizer-tutorial-part-1/}},
}
@misc{web-try-on-motivation,
	title        = {The True Cost of Apparel Returns: Alarming Return Rates Require Loss-Minimization Solutions},
	note         = {Accessed: 2023-07-30},
	howpublished = {\url{https://coresight.com/research/the-true-cost-of-apparel-returns-alarming-return-rates-require-loss-minimization-solutions/}},
}
@misc{web-recommendation-motivation,
	title        = {Ace Your Product Recommendations to Grow Revenue},
	note         = {Accessed: 2023-07-30},
	howpublished = {\url{https://www.visenze.com/blog/2023/07/19/ace-your-product-recommendations-to-grow-revenue}},
}
